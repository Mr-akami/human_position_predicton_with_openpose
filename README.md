# human_position_predicton_with_openpose
連続回避本能現象（正面から歩いてきた人とのフェイントの掛け合い）を回避するためのアプリ。

【環境】
Visual Studio 2015(VS以外の環境だと、カレントディレクトリをソース上で指定しないといけないかも)   
pyhton 3.5  
tensorflow1.4.0  

## human_position_predicton_with_openpose

【概要】  
動画から10フレーム分を学習し、10フレーム後（可変）の位置を推定する。

【入力】  
case１．Raspberry Piがカメラで撮影し、sambaサーバにフレームごとに映像を出力された画像を入力とする  
case２．PCのWebカメラでキャプチャした映像を入力とする  

【出力】  
Case1.キャプチャした画像に現在の重心位置と推定の重心位置を重畳する 
Case2.重心位置と推定の重心位置を重畳する  

【フロー】  
以下を無限ループ  
・指定フォルダを監視  
・ファイル（画像）追加されたらOpenposeで人体検出＆関節位置をJson化  
・データを整形し、機械学習にかける  
・結果を出力  

【準備】  
・「EstimateTrainig」で作成した機械学習のモデルと重みを「model」フォルダにおく  
・環境に合わせてソース内で各種ディレクトリパスを指定  
・RaspberryPi使用かWebカメラ使用かはコメントアウトで選択  

## EstimateTrainig

【概要】  
human_position_predicton_with_openposeで使用するための機械学習モデルと重みをトレーニングし出力する  

【入力】  
Openposeから出力されたJsonファイル  

【出力】  
機械学習のモデルと重み  

【処理フロー】  
・指定したフォルダ内のjsonファイルを取得  
・整形し、トレーニングデータと正解データに分別する  
・・データ整形：1行：：各関節54点、10フレーム計540点、1列：：動画が終わるまで1フレーム進めて列に追加  
・・正解データ：トレーニングデータの前指定フレーム分（=kFutureFrame）を削除  
・・トレーニングデータ：正解データとあわせるために後ろを指定フレーム分(=kFutureFrame)削除  
・モデルと重みを出力  
